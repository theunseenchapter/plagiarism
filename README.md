# üéì NLP-Powered Plagiarism Detection System

A sophisticated plagiarism detection web application that uses advanced Natural Language Processing (NLP) techniques to analyze text for potential plagiarism indicators.

## üöÄ Features

- **Single-text analysis** for plagiarism detection
- **Advanced NLP algorithms** using 12+ different techniques
- **Real-time analysis** with detailed scoring
- **Modern web interface** with responsive design
- **Comprehensive reporting** with specific issue identification

## üß† How It Uses NLP (Natural Language Processing)

### Core NLP Techniques Implemented

#### 1. **Linguistic Preprocessing**
- **Text Normalization & Cleaning**: Standardizes text format for consistent analysis
- **Case normalization**, punctuation removal, whitespace handling
- **Example**: `"Hello, World!"` ‚Üí `"hello world"`

#### 2. **Tokenization** 
- **Word Tokenization**: Splits text into individual words using NLTK
- **Sentence Segmentation**: Identifies sentence boundaries
- **Example**: `"Hello world. How are you?"` ‚Üí `['Hello', 'world']` + 2 sentences

#### 3. **Lexical Analysis**
- **Vocabulary Analysis**: Studies word usage patterns and frequency
- **Stop Words Filtering**: Removes common words (the, and, is, etc.)
- **Word Frequency Distribution**: Analyzes repetitive patterns

#### 4. **Morphological Processing**
- **Word Normalization**: Handles different word forms
- **Case-insensitive matching**: Treats "Napoleon" and "napoleon" as same
- **Alphanumeric filtering**: Focuses on meaningful words

#### 5. **N-gram Analysis**
- **Unigrams**: Individual word analysis
- **Bigrams**: Two-word phrase patterns
- **Trigrams**: Three-word phrase sequences
- **Example**: `"machine learning algorithms"` generates multiple n-grams

#### 6. **Semantic Vectorization (TF-IDF)**
- **Term Frequency-Inverse Document Frequency**: Converts text to mathematical vectors
- **Scikit-learn TfidfVectorizer**: Professional-grade implementation
- **Vector Space Model**: Enables mathematical text comparison
- **Example**: Text becomes vector `[0.2, 0.8, 0.3, ...]` representing semantic meaning

#### 7. **Pattern Recognition**
- **Regular Expression Matching**: Detects suspicious patterns
- **Citation Indicators**: `[1]`, `(2020)`, `et al.`, `doi:`
- **URL/Reference Detection**: `http://`, `www.`, `wikipedia`
- **Academic Phrases**: `"according to"`, `"studies have shown"`

#### 8. **Syntactic Analysis**
- **Sentence Structure Analysis**: Examines length and complexity
- **Grammar Pattern Detection**: Identifies inconsistent structures
- **Sentence Length Variance**: Detects copy-paste indicators
- **Writing Style Consistency**: Measures structural uniformity

#### 9. **Discourse Analysis**
- **Text Flow Examination**: Analyzes how ideas connect
- **Coherence Checking**: Detects abrupt topic changes
- **Writing Style Consistency**: Identifies inconsistent tone/style
- **Paragraph Structure**: Evaluates organization patterns

#### 10. **Genre Classification**
- **Text Type Identification**: Recognizes encyclopedia vs. personal writing
- **Wikipedia-style Detection**: Identifies reference-like content
- **Academic Writing Recognition**: Detects formal scholarly language
- **Historical Content Classification**: Identifies biographical/historical text

#### 11. **Statistical Linguistics**
- **Vocabulary Diversity Metrics**: Measures unique word ratio
- **Word Frequency Analysis**: Statistical distribution patterns
- **Mathematical Text Analysis**: Quantitative authenticity measures
- **Entropy Calculations**: Measures text randomness/predictability

#### 12. **Pragmatic Analysis**
- **Context Understanding**: Infers text purpose and intent
- **Content Classification**: Determines if text resembles references
- **Intention Recognition**: Distinguishes original vs. copied content
- **Semantic Intent Analysis**: Understands underlying meaning

## ÔøΩ Advanced Detection Algorithms

### Historical/Biographical Content Detection
```python
# Detects patterns like:
- Years: "1805", "1800s"
- Dates: "June 18, 1815"
- Titles: "Emperor", "General", "Admiral"
- Historical terms: "Battle of", "Empire", "defeated"
- Military terms: "army", "naval forces", "invasion"
```

### Wikipedia-Style Content Recognition
```python
# Identifies encyclopedia patterns:
- Factual statements: "X is a Y that..."
- Biographical markers: "was born in", "is known for"
- Reference style: "according to sources"
- Temporal markers: "as of 2020"
- Historical narrative: "led to the", "forcing X to Y"
```

### Academic Writing Indicators
```python
# Detects formal academic language:
- Transition phrases: "furthermore", "moreover", "however"
- Research language: "studies have shown", "research indicates"
- Citation patterns: "[1]", "et al.", "pp. 123"
- Formal connectors: "consequently", "subsequently"
```

## üèÜ Technical Implementation

### NLP Libraries Used
- **NLTK (Natural Language Toolkit)**: Tokenization, stop words, sentence segmentation
- **Scikit-learn**: TF-IDF vectorization, cosine similarity, feature extraction
- **Regular Expressions**: Pattern matching for citations and academic phrases
- **Collections Counter**: Word frequency analysis and statistical linguistics
- **NumPy**: Mathematical operations on text vectors

### Machine Learning Integration
- **Feature Engineering**: Converting linguistic features into ML-usable data
- **Vector Space Models**: Mathematical text representation
- **Similarity Metrics**: Semantic similarity computation
- **Classification Algorithms**: Risk level categorization
- **Ensemble Methods**: Combining multiple NLP approaches

## üìä Scoring Algorithm

### Risk Level Calculation
- **High Risk (60-100%)**: Strong plagiarism indicators detected
- **Medium Risk (35-59%)**: Moderate suspicious patterns
- **Low Risk (15-34%)**: Minor concerns identified
- **Very Low Risk (0-14%)**: Likely original content

### Scoring Factors
1. **Vocabulary Diversity** (25% weight)
2. **Suspicious Patterns** (40% weight) 
3. **Sentence Structure** (15% weight)
4. **Academic Phrases** (20% weight)
5. **Content Classification** (25% weight)
6. **Statistical Anomalies** (15% weight)

## üéØ Why This is Advanced NLP

### Comparison to Simple Text Matching

| Simple Approach | Our NLP Approach |
|----------------|------------------|
| ‚ùå Exact text matches only | ‚úÖ Semantic understanding and pattern recognition |
| ‚ùå Case sensitive ("Hello" ‚â† "hello") | ‚úÖ Normalized analysis (same meaning detected) |
| ‚ùå Cannot detect paraphrasing | ‚úÖ Semantic similarity and suspicious patterns |
| ‚ùå No context awareness | ‚úÖ Genre classification and context analysis |
| ‚ùå Word-by-word comparison | ‚úÖ Linguistic structure and discourse analysis |

### Research-Based Techniques
- **Computational Linguistics**: Established NLP algorithms
- **Information Retrieval**: TF-IDF and vector space models
- **Text Mining**: Statistical pattern recognition
- **Machine Learning**: Supervised and unsupervised approaches
- **Natural Language Understanding**: Context and semantic analysis

## üõ†Ô∏è Installation & Setup

1. **Clone or download** the project files
2. **Install dependencies**:
   ```bash
   pip install flask nltk scikit-learn numpy
   ```
3. **Run the application**:
   ```bash
   python app.py
   ```
4. **Open browser** to `http://localhost:5000`

## üìÅ Project Structure

```
NLP/
‚îú‚îÄ‚îÄ app.py              # Main Flask application with NLP algorithms
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îî‚îÄ‚îÄ index.html      # Single-text input interface
‚îú‚îÄ‚îÄ static/
‚îÇ   ‚îú‚îÄ‚îÄ css/style.css   # Modern responsive styling
‚îÇ   ‚îî‚îÄ‚îÄ js/main.js      # Frontend JavaScript functionality
‚îî‚îÄ‚îÄ README.md           # This comprehensive documentation
```

## üß™ Example Analysis Results

### Input Text (Napoleon Biography)
```
Napoleon Bonaparte was a French military general and political leader who rose to prominence 
during the French Revolution and led several successful campaigns during the Revolutionary Wars...
```

### NLP Analysis Output
- **Plagiarism Score**: 100% (High Risk)
- **Issues Detected**:
  - Encyclopedia-style patterns (12 indicators)
  - Historical content markers (18 indicators) 
  - Formal academic language detected
  - Wikipedia-like sentence structures
- **Text Statistics**: 150 words, 8 sentences, 65% vocabulary diversity

## üéì Educational Value

This project demonstrates:
- **Real-world NLP applications**
- **Multiple algorithmic approaches**
- **Professional software development**
- **Machine learning integration**
- **Web application development**
- **Statistical text analysis**

## üîÆ Future Enhancements

- **Multi-language support** using polyglot NLP
- **Database integration** for reference text comparison
- **API endpoints** for programmatic access
- **Advanced ML models** (BERT, GPT integration)
- **Plagiarism source identification**
- **Real-time collaborative detection**

---

**Built with ‚ù§Ô∏è using advanced NLP and machine learning techniques**

*This system represents a sophisticated implementation of computational linguistics for practical plagiarism detection.*

**Response:**
```json
{
    "overall_similarity": 75.5,
    "plagiarism_level": "Medium",
    "risk_color": "warning",
    "suspicious_sentences": [...],
    "word_analysis": {...},
    "total_suspicious_sentences": 3
}
```

## Important Notes

### Limitations
- This tool detects text similarity, not intent to plagiarize
- Common phrases and technical terms may show high similarity
- Results should be interpreted by knowledgeable individuals
- Designed for educational and research purposes

### Best Practices
- Always verify results with manual review
- Consider context when interpreting similarity scores
- Use multiple detection methods for comprehensive analysis
- Understand that legitimate sources may share common language

## Troubleshooting

### Common Issues
1. **NLTK Data Error**: The app automatically downloads required data on first run
2. **Port Already in Use**: Change the port in `app.py` if 5000 is occupied
3. **Memory Issues**: Large texts may require more system memory

### Performance Tips
- Keep text inputs reasonable in size (under 10,000 words)
- Close other applications if experiencing slow performance
- Use modern browsers for best experience

## Contributing

This project welcomes contributions! Areas for improvement:
- Additional similarity algorithms
- Web scraping for online plagiarism detection
- PDF/document upload support
- Batch processing capabilities
- Enhanced visualization features

## License

This project is provided for educational purposes. Please ensure compliance with your institution's academic integrity policies when using plagiarism detection tools.

## Support

For issues or questions:
1. Check the troubleshooting section
2. Review the error messages in the browser console
3. Ensure all dependencies are properly installed
4. Verify Python version compatibility

---

**Built with ‚ù§Ô∏è using Python, Flask, NLTK, and modern web technologies**
